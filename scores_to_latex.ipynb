{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_scores = \"runs_automatic_optimalv3_stemindex_nostemquery/\"\n",
    "#path_to_scores = \"runs_automatic_optimalv3_nostem/\"\n",
    "path_to_scores = \"runs_final/without_stemming/-pickAvgIDF/\"\n",
    "overleaf_output = []\n",
    "for file in os.listdir(path_to_scores):\n",
    "    if file[-6:] == \"scores\":\n",
    "\n",
    "        # bm25, optimal\n",
    "        #if not(\"bm25.\" in file and \".optimal.\" in file): \n",
    "        #    continue\n",
    "\n",
    "        # bm25, non optimal\n",
    "        #if not(\"wordnet.\" in file and \"bm25.\" in file):\n",
    "        #    continue\n",
    "\n",
    "        # bm25s, optimal\n",
    "        #if not(\"optimal.\" in file and \"bm25s.\" in file):\n",
    "        #    continue\n",
    "\n",
    "        # bm25s, not optimal\n",
    "        if not(\"wordnet.\" in file and \"bm25s.\" in file):\n",
    "           continue\n",
    "\n",
    "\n",
    "        scores = []\n",
    "        with open(path_to_scores + file, \"r\") as f:\n",
    "            for line in f:\n",
    "                scores.append(line.strip(\"\\n\").split())\n",
    "        split_scores = file.split(\".\")\n",
    "        disk = split_scores[1]\n",
    "        queries = split_scores[2]\n",
    "        source = split_scores[3]\n",
    "        weight = split_scores[4]\n",
    "        if split_scores[5] in [\"1\",\"5\"]:\n",
    "            weight += \".\" + split_scores[5]\n",
    "            method = split_scores[6]\n",
    "        else:\n",
    "            method = split_scores[5]\n",
    "\n",
    "        if \"_\" in weight:\n",
    "            weight = \"\\_\".join(weight.split(\"_\"))\n",
    "        map =  scores[0][2]\n",
    "        p30 = scores[1][2]\n",
    "        recall = scores[2][2]\n",
    "\n",
    "        overleaf_output.append([disk,queries,source,weight,method,map,p30,recall])\n",
    "\n",
    "\n",
    "sorted_overleaf_output = sorted(overleaf_output, reverse=True, key=lambda x: float(x[-1]))\n",
    "sorted_overleaf_output = [\"Disk & Queries & Expansion Source & Weighting & Method & MAP & P@30 & R@1000 \\\\\\\\\"] + [\"\\\\hline\"] + [\" & \".join(x) + \"\\\\\\\\\" for x in sorted_overleaf_output]\n",
    "for line in sorted_overleaf_output:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disk:  covid\n",
      "Disk & Queries & Expansion Source & IDF & Weighting & Method & MAP & P@30 & R@1000 \\\\\n",
      "\\hline\n",
      "Disk:  cran\n",
      "Disk & Queries & Expansion Source & IDF & Weighting & Method & MAP & P@30 & R@1000 \\\\\n",
      "\\hline\n",
      "Disk:  disk12\n",
      "Disk & Queries & Expansion Source & IDF & Weighting & Method & MAP & P@30 & R@1000 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "base_path = \"runs_final/without_stemming/\"\n",
    "idfs = [\"-idfUnion/\", \"-originalidf/\", \"-pickAvgIDF/\", \"-pickLargerIDF/\", \"-pickSmallerIDF/\"]\n",
    "idfs = [\"-originalidf/\"]\n",
    "overleaf_output = {\"covid\": [], \"cran\": [], \"disk12\": []}\n",
    "metric = -3 # recall = -1, p@30 = -2, map = -3\n",
    "\n",
    "for idf in idfs:\n",
    "    path_to_scores = base_path + idf\n",
    "    for file in os.listdir(path_to_scores):\n",
    "\n",
    "        if \"bm25.\" not in file: continue\n",
    "\n",
    "\n",
    "        if file[-6:] == \"scores\":\n",
    "            scores = []\n",
    "            with open(path_to_scores + file, \"r\") as f:\n",
    "                for line in f:\n",
    "                    scores.append(line.strip(\"\\n\").split())\n",
    "            split_scores = file.split(\".\")\n",
    "            disk = split_scores[1]\n",
    "            queries = split_scores[2]\n",
    "            source = split_scores[3]\n",
    "            weight = split_scores[4]\n",
    "            if split_scores[5] in [\"1\",\"5\"]:\n",
    "                weight += \".\" + split_scores[5]\n",
    "                method = split_scores[6]\n",
    "            else:\n",
    "                method = split_scores[5]\n",
    "\n",
    "            if \"_\" in weight:\n",
    "                weight = \"\\_\".join(weight.split(\"_\"))\n",
    "            try:\n",
    "                map =  scores[0][2]\n",
    "                p30 = scores[1][2]\n",
    "                recall = scores[2][2]\n",
    "\n",
    "                overleaf_output[disk].append([disk,queries,source,idf[:-1],weight,method,map,p30,recall])\n",
    "            except:\n",
    "                print(\"ILL-FORMATTED SCORES: \", file, idf)\n",
    "\n",
    "for disk in overleaf_output:\n",
    "    sorted_overleaf_output = sorted(overleaf_output[disk], reverse=True, key=lambda x: float(x[metric]))\n",
    "    sorted_overleaf_output = [\"Disk & Queries & Expansion Source & IDF & Weighting & Method & MAP & P@30 & R@1000 \\\\\\\\\"] + [\"\\\\hline\"] + [\" & \".join(x) + \"\\\\\\\\\" for x in sorted_overleaf_output]\n",
    "    print(\"Disk: \", disk)\n",
    "    for line in sorted_overleaf_output:\n",
    "        print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
