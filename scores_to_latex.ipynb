{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disk & Queries & Expansion Source & Weighting & Method & MAP & P@10 & R@1000 \\\\\n",
      "\\hline\n",
      "disk12 & 51-100 & wordnet & contextual\\_mean & bm25s & 0.1960 & 0.4680 & 0.4527\\\\\n",
      "disk12 & 51-100 & wordnet & 0.5 & bm25s & 0.1927 & 0.4780 & 0.4448\\\\\n",
      "disk12 & 51-100 & wordnet & contextual\\_term & bm25s & 0.1923 & 0.4760 & 0.4429\\\\\n",
      "disk12 & 51-100 & wordnet & wordnet\\_wup & bm25s & 0.1936 & 0.4600 & 0.4409\\\\\n",
      "disk12 & 51-100 & wordnet & wordnet\\_path & bm25s & 0.1936 & 0.4600 & 0.4409\\\\\n",
      "disk12 & 51-100 & wordnet & 0.1 & bm25s & 0.1920 & 0.4600 & 0.4378\\\\\n",
      "disk12 & 51-100 & wordnet & 0 & bm25s & 0.1905 & 0.4620 & 0.4253\\\\\n",
      "disk12 & 51-100 & wordnet & 1 & bm25s & 0.1783 & 0.4740 & 0.3967\\\\\n"
     ]
    }
   ],
   "source": [
    "#path_to_scores = \"runs_automatic_optimalv3_stemindex_nostemquery/\"\n",
    "#path_to_scores = \"runs_automatic_optimalv3_nostem/\"\n",
    "path_to_scores = \"runs_final/with_stemming/-originalidf/\"\n",
    "overleaf_output = []\n",
    "for file in os.listdir(path_to_scores):\n",
    "    if file[-6:] == \"scores\":\n",
    "        if \"covid\" in file: continue\n",
    "\n",
    "        # bm25, optimal\n",
    "        #if not(\"bm25.\" in file and \".optimal.\" in file): \n",
    "        #    continue\n",
    "\n",
    "        # bm25, non optimal\n",
    "        #if not(\"wordnet.\" in file and \"bm25.\" in file):\n",
    "        #    continue\n",
    "\n",
    "        # bm25s, optimal\n",
    "        #if not(\"optimal.\" in file and \"bm25s.\" in file):\n",
    "        #    continue\n",
    "\n",
    "        # bm25s, not optimal\n",
    "        if not(\"wordnet.\" in file and \"bm25s.\" in file):\n",
    "           continue\n",
    "\n",
    "\n",
    "        scores = []\n",
    "        with open(path_to_scores + file, \"r\") as f:\n",
    "            for line in f:\n",
    "                if \"all\\t\" not in line: continue\n",
    "                scores.append(line.strip(\"\\n\").split())\n",
    "        split_scores = file.split(\".\")\n",
    "        disk = split_scores[1]\n",
    "        if disk == \"cran\": continue\n",
    "        queries = split_scores[2]\n",
    "        source = split_scores[3]\n",
    "        weight = split_scores[4]\n",
    "        if split_scores[5] in [\"1\",\"5\"]:\n",
    "            weight += \".\" + split_scores[5]\n",
    "            method = split_scores[6]\n",
    "        else:\n",
    "            method = split_scores[5]\n",
    "\n",
    "        if \"_\" in weight:\n",
    "            weight = \"\\_\".join(weight.split(\"_\"))\n",
    "        map =  scores[0][2]\n",
    "        p30 = scores[1][2]\n",
    "        recall = scores[2][2]\n",
    "\n",
    "        overleaf_output.append([disk,queries,source,weight,method,map,p30,recall])\n",
    "\n",
    "\n",
    "sorted_overleaf_output = sorted(overleaf_output, reverse=True, key=lambda x: float(x[-1]))\n",
    "sorted_overleaf_output = [\"Disk & Queries & Expansion Source & Weighting & Method & MAP & P@10 & R@1000 \\\\\\\\\"] + [\"\\\\hline\"] + [\" & \".join(x) + \"\\\\\\\\\" for x in sorted_overleaf_output]\n",
    "for line in sorted_overleaf_output:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILL-FORMATTED SCORES:  run.disk12.51-100.wordnet.wordnet_wup.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.disk12.51-100.wordnet.wordnet_path.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.disk12.51-100.wordnet.0.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.disk12.51-100.wordnet.0.1.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.disk12.51-100.wordnet.0.5.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.disk12.51-100.wordnet.1.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.disk12.51-100.wordnet.contextual_mean.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.disk12.51-100.wordnet.contextual_term.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.covid.round1.wordnet.wordnet_wup.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.covid.round1.wordnet.wordnet_path.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.covid.round1.wordnet.0.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.covid.round1.wordnet.0.1.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.covid.round1.wordnet.0.5.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.covid.round1.wordnet.1.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.covid.round1.wordnet.contextual_mean.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.covid.round1.wordnet.contextual_term.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.disk12.51-100.optimal.0.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.disk12.51-100.optimal.0.1.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.disk12.51-100.optimal.0.5.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.disk12.51-100.optimal.keep_optimal.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.disk12.51-100.optimal.norm_across_query.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.disk12.51-100.optimal.2.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.disk12.51-100.optimal.5.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.disk12.51-100.optimal.1.1.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.disk12.51-100.optimal.1.2.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.disk12.51-100.optimal.1.5.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.covid.round1.optimal.0.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.covid.round1.optimal.0.1.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.covid.round1.optimal.0.5.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.covid.round1.optimal.1.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.covid.round1.optimal.keep_optimal.bm25.txt.scores -idfUnion/\n",
      "ILL-FORMATTED SCORES:  run.covid.round1.optimal.norm_across_query.bm25.txt.scores -idfUnion/\n",
      "Disk:  covid\n",
      "Disk & Queries & Expansion Source & IDF & Weighting & Method & MAP & P@10 & R@1000 \\\\\n",
      "\\hline\n",
      "wordnet & 0.5 & TF-Merging & 0.0257 & 0.1033 & 0.3083\\\\\n",
      "BERT & 0.1 & TF-Merging & 0.0255 & 0.1067 & 0.3105\\\\\n",
      "wordnet & contextual term & TF-Merging & 0.0255 & 0.1000 & 0.3085\\\\\n",
      "wordnet & wordnet wup & TF-Merging & 0.0254 & 0.1100 & 0.2974\\\\\n",
      "wordnet & wordnet path & TF-Merging & 0.0254 & 0.1100 & 0.2974\\\\\n",
      "wordnet & contextual mean & TF-Merging & 0.0254 & 0.1033 & 0.3073\\\\\n",
      "wordnet & 0.1 & TF-Merging & 0.0253 & 0.1100 & 0.3051\\\\\n",
      "BERT & 0 & TF-Merging & 0.0252 & 0.1100 & 0.3044\\\\\n",
      "wordnet & 0 & TF-Merging & 0.0252 & 0.1100 & 0.3044\\\\\n",
      "BERT & Normalization & TF-Merging & 0.0247 & 0.0967 & 0.3096\\\\\n",
      "BERT & 0.5 & TF-Merging & 0.0230 & 0.0833 & 0.3121\\\\\n",
      "BERT & keep optimal & TF-Merging & 0.0221 & 0.0800 & 0.3065\\\\\n",
      "BERT & 1 & TF-Merging & 0.0220 & 0.0633 & 0.2651\\\\\n",
      "wordnet & 1 & TF-Merging & 0.0216 & 0.0867 & 0.2879\\\\\n",
      "wordnet & contextual term & bm25 & 0.0162 & 0.0833 & 0.1958\\\\\n",
      "wordnet & contextual mean & bm25 & 0.0161 & 0.0900 & 0.1876\\\\\n",
      "BERT & 0.1 & bm25 & 0.0160 & 0.0900 & 0.1766\\\\\n",
      "wordnet & wordnet wup & bm25 & 0.0158 & 0.0933 & 0.1813\\\\\n",
      "wordnet & wordnet path & bm25 & 0.0158 & 0.0933 & 0.1813\\\\\n",
      "BERT & 0.5 & bm25 & 0.0157 & 0.0867 & 0.1730\\\\\n",
      "BERT & Normalization & bm25 & 0.0157 & 0.0900 & 0.1729\\\\\n",
      "wordnet & 0.5 & bm25 & 0.0157 & 0.0800 & 0.1857\\\\\n",
      "wordnet & 0.1 & bm25 & 0.0151 & 0.0967 & 0.1787\\\\\n",
      "BERT & keep optimal & bm25 & 0.0150 & 0.0800 & 0.1733\\\\\n",
      "BERT & 0 & bm25 & 0.0149 & 0.0933 & 0.1742\\\\\n",
      "wordnet & 0 & bm25 & 0.0149 & 0.0933 & 0.1742\\\\\n",
      "wordnet & 1 & bm25 & 0.0141 & 0.0733 & 0.1878\\\\\n",
      "BERT & 1 & bm25 & 0.0126 & 0.0767 & 0.1673\\\\\n",
      "Disk:  cran\n",
      "Disk & Queries & Expansion Source & IDF & Weighting & Method & MAP & P@10 & R@1000 \\\\\n",
      "\\hline\n",
      "Disk:  disk12\n",
      "Disk & Queries & Expansion Source & IDF & Weighting & Method & MAP & P@10 & R@1000 \\\\\n",
      "\\hline\n",
      "BERT & Normalization & bm25 & 0.1996 & 0.4820 & 0.4577\\\\\n",
      "wordnet & contextual mean & bm25 & 0.1988 & 0.4680 & 0.4527\\\\\n",
      "BERT & 0.1 & bm25 & 0.1979 & 0.4700 & 0.4457\\\\\n",
      "wordnet & contextual term & TF-Merging & 0.1947 & 0.4660 & 0.4429\\\\\n",
      "wordnet & 0.1 & bm25 & 0.1945 & 0.4640 & 0.4378\\\\\n",
      "BERT & 0.5 & bm25 & 0.1929 & 0.4960 & 0.4622\\\\\n",
      "BERT & 0 & bm25 & 0.1908 & 0.4620 & 0.4253\\\\\n",
      "wordnet & 0 & bm25 & 0.1908 & 0.4620 & 0.4253\\\\\n",
      "wordnet & contextual mean & TF-Merging & 0.1898 & 0.4660 & 0.4527\\\\\n",
      "wordnet & 0.5 & TF-Merging & 0.1890 & 0.4700 & 0.4448\\\\\n",
      "wordnet & 0.5 & bm25 & 0.1887 & 0.4560 & 0.4437\\\\\n",
      "BERT & 0.5 & TF-Merging & 0.1882 & 0.4620 & 0.4620\\\\\n",
      "BERT & keep optimal & TF-Merging & 0.1865 & 0.4580 & 0.4526\\\\\n",
      "BERT & Normalization & TF-Merging & 0.1864 & 0.4560 & 0.4579\\\\\n",
      "wordnet & wordnet wup & bm25 & 0.1863 & 0.4440 & 0.4407\\\\\n",
      "wordnet & wordnet path & bm25 & 0.1863 & 0.4440 & 0.4407\\\\\n",
      "wordnet & contextual term & bm25 & 0.1859 & 0.4620 & 0.4429\\\\\n",
      "wordnet & wordnet wup & TF-Merging & 0.1856 & 0.4640 & 0.4406\\\\\n",
      "wordnet & wordnet path & TF-Merging & 0.1856 & 0.4640 & 0.4406\\\\\n",
      "BERT & keep optimal & bm25 & 0.1843 & 0.4900 & 0.4537\\\\\n",
      "wordnet & 1 & TF-Merging & 0.1834 & 0.4740 & 0.3967\\\\\n",
      "BERT & 0.1 & TF-Merging & 0.1820 & 0.4580 & 0.4456\\\\\n",
      "wordnet & 0.1 & TF-Merging & 0.1810 & 0.4600 & 0.4378\\\\\n",
      "BERT & 0 & TF-Merging & 0.1785 & 0.4600 & 0.4253\\\\\n",
      "wordnet & 0 & TF-Merging & 0.1785 & 0.4600 & 0.4253\\\\\n",
      "BERT & 1 & TF-Merging & 0.1744 & 0.4540 & 0.4231\\\\\n",
      "BERT & 1.1 & TF-Merging & 0.1679 & 0.4340 & 0.4123\\\\\n",
      "BERT & 1 & bm25 & 0.1650 & 0.4560 & 0.4227\\\\\n",
      "BERT & 1 & bm25 & 0.1650 & 0.4560 & 0.4227\\\\\n",
      "BERT & 1.2 & TF-Merging & 0.1601 & 0.3920 & 0.4011\\\\\n",
      "BERT & 1.1 & bm25 & 0.1598 & 0.4500 & 0.4123\\\\\n",
      "BERT & 1.2 & bm25 & 0.1548 & 0.4420 & 0.4013\\\\\n",
      "wordnet & 1 & bm25 & 0.1489 & 0.3920 & 0.3932\\\\\n",
      "BERT & 1.5 & bm25 & 0.1425 & 0.4420 & 0.3737\\\\\n",
      "BERT & 1.5 & TF-Merging & 0.1344 & 0.3080 & 0.3737\\\\\n",
      "BERT & 2 & bm25 & 0.1286 & 0.4180 & 0.3397\\\\\n",
      "BERT & 2 & TF-Merging & 0.1131 & 0.2160 & 0.3402\\\\\n",
      "BERT & 5 & bm25 & 0.1051 & 0.3400 & 0.2803\\\\\n",
      "BERT & 5 & TF-Merging & 0.0900 & 0.1620 & 0.2803\\\\\n"
     ]
    }
   ],
   "source": [
    "base_path = \"runs_final/without_stemming/\"\n",
    "idfs = [\"-idfUnion/\", \"-originalidf/\", \"-pickAvgIDF/\", \"-pickLargerIDF/\", \"-pickSmallerIDF/\"]\n",
    "idfs = [\"-idfUnion/\", \"-originalidf/\"]\n",
    "overleaf_output = {\"covid\": [], \"cran\": [], \"disk12\": []}\n",
    "metric = -3 # recall = -1, p@30 = -2, map = -3\n",
    "\n",
    "for idf in idfs:\n",
    "    path_to_scores = base_path + idf\n",
    "    for file in os.listdir(path_to_scores):\n",
    "\n",
    "        #if \"bm25s.\" not in file: continue\n",
    "\n",
    "\n",
    "        if file[-6:] == \"scores\":\n",
    "            scores = []\n",
    "            with open(path_to_scores + file, \"r\") as f:\n",
    "                for line in f:\n",
    "                    if \"all\\t\" not in line: continue\n",
    "                    scores.append(line.strip(\"\\n\").split())\n",
    "            split_scores = file.split(\".\")\n",
    "            disk = split_scores[1]\n",
    "            if disk == \"cran\": continue\n",
    "\n",
    "            queries = split_scores[2]\n",
    "            source = split_scores[3]\n",
    "            weight = split_scores[4]\n",
    "            if split_scores[5] in [\"1\", \"2\",\"5\"]:\n",
    "                weight += \".\" + split_scores[5]\n",
    "                method = split_scores[6]\n",
    "            else:\n",
    "                method = split_scores[5]\n",
    "\n",
    "            if \"_\" in weight:\n",
    "                weight = \" \".join(weight.split(\"_\"))\n",
    "                #weight = \"\\_\".join(weight.split(\"_\"))\n",
    "            try:\n",
    "                map =  scores[0][2]\n",
    "                p30 = scores[1][2]\n",
    "                recall = scores[2][2]\n",
    "\n",
    "                if weight == \"norm across query\":\n",
    "                    weight = \"Normalization\"\n",
    "                if source == \"optimal\":\n",
    "                    source = \"BERT\"\n",
    "                if method == \"bm25s\":\n",
    "                    method = \"TF-Merging\"\n",
    "\n",
    "                if method == \"TF-Merging\" and idf[:-1] == \"-originalidf\": continue\n",
    "                \n",
    "\n",
    "\n",
    "                overleaf_output[disk].append([source,weight,method,map,p30,recall])\n",
    "                #overleaf_output[disk].append([disk,queries,source,idf[:-1],weight,method,map,p30,recall])\n",
    "            except:\n",
    "                print(\"ILL-FORMATTED SCORES: \", file, idf)\n",
    "\n",
    "for disk in overleaf_output:\n",
    "    sorted_overleaf_output = sorted(overleaf_output[disk], reverse=True, key=lambda x: float(x[metric]))\n",
    "    sorted_overleaf_output = [\"Disk & Queries & Expansion Source & IDF & Weighting & Method & MAP & P@10 & R@1000 \\\\\\\\\"] + [\"\\\\hline\"] + [\" & \".join(x) + \"\\\\\\\\\" for x in sorted_overleaf_output]\n",
    "    print(\"Disk: \", disk)\n",
    "    for line in sorted_overleaf_output:\n",
    "        print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
